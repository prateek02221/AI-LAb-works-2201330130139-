{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+iThgoGrT9bLj+jrdklFK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycL2FV1aig_b","executionInfo":{"status":"ok","timestamp":1732257600179,"user_tz":-330,"elapsed":3391,"user":{"displayName":"Prateek Singh","userId":"15805440210592889456"}},"outputId":"cc1b5a6d-a7fb-4481-a677-6728022ca8d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (3.1.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"]}],"source":["!pip install gym\n","\n","# Import required libraries\n","import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","import glob\n","import io\n","from base64 import b64encode\n","from gym.wrappers import RecordVideo"]},{"cell_type":"code","source":["def discretize_state(state, bins):\n","    position_bins = np.linspace(-1.2, 0.6, bins)  # Discretize position\n","    velocity_bins = np.linspace(-0.07, 0.07, bins)  # Discretize velocity\n","    position_idx = np.digitize(state[0], position_bins) - 1\n","    velocity_idx = np.digitize(state[1], velocity_bins) - 1\n","    return (position_idx, velocity_idx)\n","\n","# Function to display video\n","def show_video():\n","    video_path = glob.glob('./video/*.mp4')[0]\n","    video = io.open(video_path, 'r+b').read()\n","    encoded = b64encode(video)\n","    return HTML(data=f'''\n","        ''')\n","\n","# Initialize the environment\n","env = gym.make(\"MountainCar-v0\")\n","\n","# Hyperparameters\n","n_bins = 20  # Number of bins for discretization\n","alpha = 0.1  # Learning rate\n","gamma = 0.99  # Discount factor\n","epsilon = 1.0  # Exploration rate\n","epsilon_decay = 0.995\n","epsilon_min = 0.01\n","n_episodes = 5000\n","\n","# Initialize Q-table\n","n_actions = env.action_space.n\n","q_table = np.zeros((n_bins, n_bins, n_actions))\n","\n","# Training loop\n","for episode in range(n_episodes):\n","    state = discretize_state(env.reset(), n_bins)\n","    done = False\n","    total_reward = 0\n","\n","    while not done:\n","        # Choose action: exploration vs exploitation\n","        if np.random.random() < epsilon:\n","            action = env.action_space.sample()\n","        else:\n","            action = np.argmax(q_table[state])\n","\n","        # Perform action\n","        next_state_raw, reward, done, _ = env.step(action)\n","        next_state = discretize_state(next_state_raw, n_bins)\n","\n","        # Update Q-value\n","        best_next_action = np.argmax(q_table[next_state])\n","        td_target = reward + gamma * q_table[next_state][best_next_action]\n","        q_table[state][action] += alpha * (td_target - q_table[state][action])\n","\n","        state = next_state\n","        total_reward += reward\n","\n","    # Decay epsilon\n","    if epsilon > epsilon_min:\n","        epsilon *= epsilon_decay\n","\n","    if episode % 100 == 0:\n","        print(f\"Episode {episode}, Total Reward: {total_reward}\")\n","\n","print(\"Training Complete!\")\n","\n","# Wrap environment for recording\n","env = RecordVideo(env, \"./video\", episode_trigger=lambda x: True)\n","\n","# Test the trained agent\n","state = discretize_state(env.reset(), n_bins)\n","done = False\n","while not done:\n","    action = np.argmax(q_table[state])\n","    next_state_raw, _, done, _ = env.step(action)\n","    state = discretize_state(next_state_raw, n_bins)\n","\n","env.close()\n","\n","# Display the video\n","show_video()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"somKZXh9iz7m","executionInfo":{"status":"ok","timestamp":1732257878130,"user_tz":-330,"elapsed":92545,"user":{"displayName":"Prateek Singh","userId":"15805440210592889456"}},"outputId":"1ec4910c-1bb3-470b-9bd8-0269758907f6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n","  if not isinstance(terminated, (bool, np.bool8)):\n"]},{"output_type":"stream","name":"stdout","text":["Episode 0, Total Reward: -200.0\n","Episode 100, Total Reward: -200.0\n","Episode 200, Total Reward: -200.0\n","Episode 300, Total Reward: -200.0\n","Episode 400, Total Reward: -200.0\n","Episode 500, Total Reward: -200.0\n","Episode 600, Total Reward: -200.0\n","Episode 700, Total Reward: -200.0\n","Episode 800, Total Reward: -200.0\n","Episode 900, Total Reward: -200.0\n","Episode 1000, Total Reward: -200.0\n","Episode 1100, Total Reward: -200.0\n","Episode 1200, Total Reward: -200.0\n","Episode 1300, Total Reward: -200.0\n","Episode 1400, Total Reward: -159.0\n","Episode 1500, Total Reward: -162.0\n","Episode 1600, Total Reward: -191.0\n","Episode 1700, Total Reward: -200.0\n","Episode 1800, Total Reward: -200.0\n","Episode 1900, Total Reward: -164.0\n","Episode 2000, Total Reward: -200.0\n","Episode 2100, Total Reward: -200.0\n","Episode 2200, Total Reward: -160.0\n","Episode 2300, Total Reward: -151.0\n","Episode 2400, Total Reward: -170.0\n","Episode 2500, Total Reward: -150.0\n","Episode 2600, Total Reward: -194.0\n","Episode 2700, Total Reward: -200.0\n","Episode 2800, Total Reward: -155.0\n","Episode 2900, Total Reward: -200.0\n","Episode 3000, Total Reward: -200.0\n","Episode 3100, Total Reward: -121.0\n","Episode 3200, Total Reward: -200.0\n","Episode 3300, Total Reward: -163.0\n","Episode 3400, Total Reward: -138.0\n","Episode 3500, Total Reward: -159.0\n","Episode 3600, Total Reward: -150.0\n","Episode 3700, Total Reward: -132.0\n","Episode 3800, Total Reward: -155.0\n","Episode 3900, Total Reward: -200.0\n","Episode 4000, Total Reward: -161.0\n","Episode 4100, Total Reward: -168.0\n","Episode 4200, Total Reward: -199.0\n","Episode 4300, Total Reward: -162.0\n","Episode 4400, Total Reward: -167.0\n","Episode 4500, Total Reward: -200.0\n","Episode 4600, Total Reward: -164.0\n","Episode 4700, Total Reward: -142.0\n","Episode 4800, Total Reward: -149.0\n","Episode 4900, Total Reward: -147.0\n","Training Complete!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/wrappers/record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n","  logger.warn(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment MountainCar-v0 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n","  logger.deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  deprecation(\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","        "]},"metadata":{},"execution_count":10}]}]}